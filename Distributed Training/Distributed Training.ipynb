{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ee9749-0649-4c45-bc41-5ba0ab055902",
   "metadata": {},
   "source": [
    "![banner](https://raw.githubusercontent.com/priyammaz/HAL-DL-From-Scratch/main/src/visuals/banner.png)\n",
    "\n",
    "## Distributed Training\n",
    "\n",
    "A major problem you may quickly face is the size of your models are getting too large to fit on your GPU! This makes sense as todays state-of-the-art models are tens of billions of parameters, so what do we then do? There is typically two approaches we can take depending on the issue.\n",
    "\n",
    "#### **Gradient Accumulation** \n",
    "If your model completely fills up your GPU memory where there is no space to pass in a reasonable batch size, we can use **gradient accumulation**. \n",
    "Gradient accumulation is instead of passing in a batch size of 64 all at once, pass in smaller minibatches of size 8, 8 different times. Then store all those losses and accumulate them at the end before the backward pass. \n",
    "    \n",
    "#### Data Parallelism\n",
    "\n",
    "![dataparallel](https://naga-karthik.github.io/media/ddp-figures/bothPasses.png)\n",
    "\n",
    "[credit](https://naga-karthik.github.io/post/pytorch-ddp/)\n",
    "\n",
    "If you have more than 1 GPU but the model can fit on any one of them, we can do **Data Parallelism**. What this does is make a copy of the full model to each GPU and then passes smaller batchsizes of data to push through all the models. We then accumulate this information at the end and perform backpropagation. An important aspect of this is all the weights are Synced across the GPUs so they are identical models!! Typically GPU 0 is responsible for managing the syncing between the GPUs. This will require us to spawn a bunch of parallel processes and a bunch of steps to setup.\n",
    "\n",
    "\n",
    "#### Model Parallelism\n",
    "\n",
    "![modelparallel](https://fairscale.readthedocs.io/en/latest/_images/pipe.png)\n",
    "\n",
    "[credit](https://fairscale.readthedocs.io/en/latest/deep_dive/pipeline_parallelism.html)\n",
    "\n",
    "\n",
    "If you have multiple GPUs, but your model is so large that it cannot fit on any of them, then we have to split the model up between GPUS. This means we will have the weights of the model split between the different GPU blocks. This is relatively easy to implement though with some code changes!\n",
    "\n",
    "\n",
    "### AlexNet\n",
    "AlexNet is not a very large model by any stretch of the imagination, but the ideas we will explore with this relatively simple implementation will hold true regardless of the architecture! We will be performing the things mentioned above by updating the training and model code from our [Intro to Vision Tutorial](https://github.com/priyammaz/HAL-DL-From-Scratch/tree/main/PyTorch%20for%20Computer%20Vision/Intro%20to%20Vision). Lets take a look at our starting point first copied from there and I will indicate changes for every version we explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202ff7d6-aa5f-4870-8629-9d216274d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98cc746-bfd0-45ca-bdec-068be7855798",
   "metadata": {},
   "source": [
    "#### Define Vanilla AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b52b24-fb5d-4973-9cc8-09c6b04acd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaAlexNet(nn.Module):\n",
    "    def __init__(self, classes=2, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),  \n",
    "                nn.BatchNorm2d(num_features=64), # ADDED IN BATCHNORM\n",
    "                \n",
    "                nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "                nn.BatchNorm2d(num_features=192), # ADDED IN BATCHNORM \n",
    "                \n",
    "                nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                nn.BatchNorm2d(num_features=384), # ADDED IN BATCHNORM \n",
    "                \n",
    "                \n",
    "                nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features=256), # ADDED IN BATCHNORM \n",
    "                \n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                nn.BatchNorm2d(num_features=256), # ADDED IN BATCHNORM \n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Dropout(dropout_p),\n",
    "                nn.Linear(256*6*6, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_p),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88587a1a-ed06-422c-9e96-73d972c31db6",
   "metadata": {},
   "source": [
    "#### Prep DataLoaders for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39120e6a-e2f3-4360-ac09-428cb53d4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Cats vs Dogs Dataset ###\n",
    "PATH_TO_DATA = \"../data/PetImages/\"\n",
    "\n",
    "### DEFINE TRANSFORMATIONS ###\n",
    "normalizer = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]) ### IMAGENET MEAN/STD ###\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.Resize((224,224)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalizer\n",
    "                                      ])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(PATH_TO_DATA, transform=train_transforms)\n",
    "\n",
    "train_samples, test_samples = int(0.9 * len(dataset)), len(dataset) - int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, lengths=[train_samples, test_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a96d3b-6802-4e2b-8ec6-cba5b84e5d66",
   "metadata": {},
   "source": [
    "#### Default Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc7a650-1b50-41b0-a49a-86055e490c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Device cuda\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:29<00:00,  6.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5134251930496909\n",
      "Validation Loss: 0.41623771488666533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### SELECT DEVICE ###\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on Device {DEVICE}\")\n",
    "\n",
    "### LOAD IN AlexNet ###\n",
    "model = VanillaAlexNet()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 1\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def vanilla_train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        \n",
    "        model.train() # Turn On BatchNorm and Dropout\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "        \n",
    "            ### CALCULATE LOSS ##\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval() # Turn Off Batchnorm \n",
    "        for image, label in tqdm(valloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "\n",
    "                ### CALCULATE LOSS ##\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "\n",
    "        training_loss_mean = np.mean(training_losses)\n",
    "        valid_loss_mean = np.mean(validation_losses)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        \n",
    "    return model\n",
    "\n",
    "model = vanilla_train(model=model,\n",
    "                      device=DEVICE,\n",
    "                      epochs=epochs,\n",
    "                      optimizer=optimizer,\n",
    "                      loss_fn=loss_fn,\n",
    "                      batch_size=batch_size,\n",
    "                      trainloader=trainloader,\n",
    "                      valloader=valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c7973-4d91-4edc-866a-6d20bb34088d",
   "metadata": {},
   "source": [
    "## Gradient Accumulation\n",
    "\n",
    "We will split our batch size of 128 up with a gradient accumulation steps and then aggregate that information at the end before backpropagation! There is one consideration though! If your batch size is too small, then the batchnorm layers wont have enough samples to work with to calcualte their mean and standard deviation. There are some workarounds for this (LayerNormalization could be one) but it is out of the scope in an introduction to these materials.\n",
    "\n",
    "\n",
    "**Downsides of Accumulation:**\n",
    "\n",
    "One thing you will see though is, beause we are splitting up our forward propagation into an iteration of steps rather in parallel, your time for training will definitely go up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba354f55-e99e-4d50-9bc2-27d7426e1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Device cuda\n",
      "Target Batch Size: 128 Split into 8 Accumulation Steps\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1403/1403 [01:33<00:00, 15.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 156/156 [00:03<00:00, 41.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.490524502828218\n",
      "Validation Loss: 0.3431617067887997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############### OLD CODE ##############\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on Device {DEVICE}\")\n",
    "model = VanillaAlexNet()\n",
    "model = model.to(DEVICE)\n",
    "epochs = 1\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#######################################\n",
    "\n",
    "\n",
    "############### NEW CODE ##############\n",
    "batch_size = 128\n",
    "gradient_accum_steps = 8 # Split up large batch size into 8 steps\n",
    "sub_batch_size = 128 // 8 # Get number of samples for each sub-batch\n",
    "print(f\"Target Batch Size: {batch_size} Split into {gradient_accum_steps} Accumulation Steps\")\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=sub_batch_size, shuffle=True, num_workers=4) # use sub batch size\n",
    "valloader = DataLoader(val_dataset, batch_size=sub_batch_size, shuffle=False, num_workers=4) # use sub batch size\n",
    "#######################################\n",
    "\n",
    "def grad_accum_train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader, gradient_accum_steps): # Add gradient accum steps\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        model.train()\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            \n",
    "            ############### NEW CODE ##############\n",
    "            accumulated_losses = 0 # Create a list to store loss values\n",
    "            accumulated_accuracies = []\n",
    "            for _ in range(gradient_accum_steps):  # Iterate through the number of steps we want\n",
    "                out = model.forward(image) # Pass through a sub batch of images\n",
    "                subloss = loss_fn(out, label) # Calculate the loss for the sub batch of images\n",
    "                accumulated_losses+=subloss # Add the loss\n",
    "                \n",
    "            loss = accumulated_losses / gradient_accum_steps # Calculate mean loss across the sub batches\n",
    "            ########################################\n",
    "            \n",
    "            training_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval() \n",
    "        for image, label in tqdm(valloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "        training_loss_mean = np.mean(training_losses)\n",
    "        valid_loss_mean = np.mean(validation_losses)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        \n",
    "    return model\n",
    "\n",
    "model = grad_accum_train(model=model,\n",
    "                         device=DEVICE,\n",
    "                         epochs=epochs,\n",
    "                         optimizer=optimizer,\n",
    "                         loss_fn=loss_fn,\n",
    "                         batch_size=batch_size,\n",
    "                         trainloader=trainloader,\n",
    "                         valloader=valloader,\n",
    "                         gradient_accum_steps=gradient_accum_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8fcad1-41cc-4b71-8b45-6c4a40ffa0b1",
   "metadata": {},
   "source": [
    "## Model Parallelism\n",
    "\n",
    "In this next stage we will be splitting our model up between 2 GPUS! This is very simple and we just need to let the model know which layers belong where. Lets first take a look at the resources we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2450ed5-356b-48a3-aa46-9f22482bc603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 26 10:15:51 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 61%   75C    P2    90W / 280W |   4874MiB / 24212MiB |     18%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   34C    P8    29W / 280W |     13MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1548      G   /usr/lib/xorg/Xorg                198MiB |\n",
      "|    0   N/A  N/A      3389      G   /usr/lib/xorg/Xorg                646MiB |\n",
      "|    0   N/A  N/A      3534      G   /usr/bin/gnome-shell               81MiB |\n",
      "|    0   N/A  N/A      7030      G   ...f_6932.log --shared-files       90MiB |\n",
      "|    0   N/A  N/A      7427      G   ...615215966282264291,131072      490MiB |\n",
      "|    0   N/A  N/A     11645      C   ...da3/envs/torch/bin/python     3285MiB |\n",
      "|    1   N/A  N/A      1548      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      3389      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736374b5-bddc-422d-93d7-4bd2f4030822",
   "metadata": {},
   "source": [
    "We can see that we have 2 GPUs, and they will each be labeled \"cuda:0\" and \"cuda:1\". So we can use those to pass our data through the model as we want. \n",
    "\n",
    "### Updated Model Code to Pipe GPU Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2418a2cd-4d5e-446f-976f-93d346921d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParallelAlexNet(nn.Module):\n",
    "    def __init__(self, classes=2, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),  \n",
    "                nn.BatchNorm2d(num_features=64), # ADDED IN BATCHNORM\n",
    "                \n",
    "                nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "                nn.BatchNorm2d(num_features=192), # ADDED IN BATCHNORM \n",
    "                \n",
    "                nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                nn.BatchNorm2d(num_features=384), # ADDED IN BATCHNORM \n",
    "                \n",
    "                \n",
    "                nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features=256), # ADDED IN BATCHNORM \n",
    "                \n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                nn.BatchNorm2d(num_features=256), # ADDED IN BATCHNORM \n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Dropout(dropout_p),\n",
    "                nn.Linear(256*6*6, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_p),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096, classes)\n",
    "        )\n",
    "        \n",
    "        ############### NEW CODE ##############\n",
    "        self.feature_extractor = self.feature_extractor.to(\"cuda:0\")\n",
    "        self.avgpool = self.avgpool.to(\"cuda:1\")\n",
    "        self.head = self.head.to(\"cuda:1\")\n",
    "        ########################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        ### MOVE X TO GPU WITH FEATURE EXTRACTOR ###\n",
    "        x = x.to(\"cuda:0\")\n",
    "        x = self.feature_extractor(x)\n",
    "        \n",
    "        \n",
    "        ### MOVE X TO GPU WITH REMAINING LAYERS ###\n",
    "        x = x.to(\"cuda:1\")\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98e1a4-bd6f-412c-918c-8c391a9518e0",
   "metadata": {},
   "source": [
    "### Training Script\n",
    "In this example, we will be passing in some tensor which in the model will be moved to GPU 0. Internally this tensor will then move to GPU 1, so we need to ensure that when we calculate the loss, our labels we are comparing against are also in GPU 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd943a27-831e-4980-afb6-9b35b202f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:29<00:00,  5.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5130078430202875\n",
      "Validation Loss: 0.41395812183618547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############### NEW CODE ##############\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # We will not set a device anymore\n",
    "# print(f\"Training on Device {DEVICE}\")\n",
    "########################################\n",
    "\n",
    "\n",
    "### LOAD IN AlexNet Model With Model Parallelism ###\n",
    "model = ModelParallelAlexNet()\n",
    "# model = model.to(DEVICE) # No longer sending the model to a device, we did that within the model itself\n",
    "\n",
    "epochs = 1\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def model_parallel_train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        \n",
    "        model.train() # Turn On BatchNorm and Dropout\n",
    "        for image, label in tqdm(trainloader):\n",
    "            \n",
    "            \n",
    "            ############### NEW CODE ##############\n",
    "            label = label.to(\"cuda:1\") # We need to ensure out label is sitting where we expect our model output\n",
    "            ########################################\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "        \n",
    "            ### CALCULATE LOSS ##\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval() # Turn Off Batchnorm \n",
    "        for image, label in tqdm(valloader):\n",
    "            \n",
    "            \n",
    "            ############### NEW CODE ##############\n",
    "            label = label.to(\"cuda:1\") # We need to ensure out label is sitting where we expect our model output\n",
    "            ########################################\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "\n",
    "                ### CALCULATE LOSS ##\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "\n",
    "        training_loss_mean = np.mean(training_losses)\n",
    "        valid_loss_mean = np.mean(validation_losses)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "model = model_parallel_train(model=model,\n",
    "                             device=DEVICE,\n",
    "                             epochs=epochs,\n",
    "                             optimizer=optimizer,\n",
    "                             loss_fn=loss_fn,\n",
    "                             batch_size=batch_size,\n",
    "                             trainloader=trainloader,\n",
    "                             valloader=valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58731b-2199-498b-a960-f0be6dc91d19",
   "metadata": {},
   "source": [
    "## Data Parallelism\n",
    "\n",
    "This is probably the easiest implementation for paralleism but it has some limitations compared to the **Distributed Data Parallelism** that we will see in a bit. Namely, DataParallel is limited to a single process on a single machine, meaning we cannot take advantage of multiple processes. Regardless, lets put it together!\n",
    "\n",
    "We will be using here the Vanilla AlexNet along with our Vanilla training function. As you can see, there is really nothing to do but wrap our model with DataParallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92bcad9e-d002-400c-a743-d03d3dfdf750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:29<00:00,  5.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5091178042983467\n",
      "Validation Loss: 0.4232334554195404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "############### NEW CODE ##############\n",
    "model = VanillaAlexNet()\n",
    "model = torch.nn.DataParallel(model, device_ids=[0,1]) # Wrap model with Data Parallel and provide IDX for GPUS we want to train on\n",
    "model = model.to(DEVICE) # Move model to the main GPU node (typically the first one)\n",
    "#######################################\n",
    "    \n",
    "epochs = 1\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "model = vanilla_train(model=model,\n",
    "                      device=DEVICE,\n",
    "                      epochs=epochs,\n",
    "                      optimizer=optimizer,\n",
    "                      loss_fn=loss_fn,\n",
    "                      batch_size=batch_size,\n",
    "                      trainloader=trainloader,\n",
    "                      valloader=valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e23807-5475-44ef-947f-05db165f0466",
   "metadata": {},
   "source": [
    "## Distributed DataParallelism\n",
    "\n",
    "Everything from here on forward is not going to work on a Jupyter Notebook. We will explore the ideas here but then the actual script that can run will be available in [ddp.py](ddp.py)\n",
    "\n",
    "There are some ideas we need to talk about first before we keep going:\n",
    "\n",
    "- **Process/Worker:** Refers to an instance of a Python program, where each process will control a single GPU.\n",
    "- **Node:** An entire computer and all its components. Training on multiple nodes means training accross multiple computers\n",
    "- **World Size**: Total number of processes participating in the compute task. Typically this is your **Number of GPUS**\n",
    "- **Global Rank**: The Unique ID assigned to each of your GPUS across all nodesl. Typically 0 is the main process\n",
    "- **Local Rank**: The Unique ID assigned to each GPU inside a single Node (only matters in multinode training, otherwise identical to Global Rank)\n",
    "\n",
    "\n",
    "#### Step 1) Setup the IP Address/Port Number for the GPUS to communicate through\n",
    "- Typically our address will be \"localhost\" and the Port can be any number you want that is not being used by your computer, we will just use 12355. These will be accessed by the multithread by reading our environmental variables, so we will update our environmental variables as such. \n",
    "- We need to initialize the process group with the rank and world size. Rank will be determined by the DDP Module so we will just have a variable for it to pass in, but we need to let it know the world size, or the number of GPUs we have access to. \n",
    "\n",
    "When we initialize the group, you will notice we are using *nccl* as our backend which stands for NVIDIA Collective Communication Library. There are some other options such as **gloo** and **mpi** but each have varying capabilities that you can explore [here](https://pytorch.org/docs/stable/distributed.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788189a6-e99c-4c63-b5bf-a06cb2b0cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import In DDP Related Packages ###\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732058d5-a4e5-4602-937a-d18766241bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053158fa-088c-4976-b185-1c7ec15930c5",
   "metadata": {},
   "source": [
    "#### Step 2) Build a Distributed Data Sampler\n",
    "\n",
    "If we want to split our dataset across multiple GPUS, we also need to be able to sample data in a distrbuted way for a specific GPU (the rank). Therefore lets build a distributed sampler DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47e883f7-3803-44ac-a121-fa800522593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_distributed_sampler(path_to_data, batch_size, world_size, rank):\n",
    "    \n",
    "    ############### OLD CODE ##############\n",
    "    dataset = ImageFolder(path_to_data)\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    train_transforms = Compose([\n",
    "        Resize((224, 224)),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        normalizer])\n",
    "\n",
    "    val_transforms = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        normalizer])\n",
    "\n",
    "    train_samples, test_samples = int(0.9 * len(dataset)), len(dataset) - int(0.9 * len(dataset))\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, lengths=[train_samples, test_samples])\n",
    "\n",
    "    train_dataset.dataset.transform = train_transforms\n",
    "    val_dataset.dataset.transform = val_transforms\n",
    "    #######################################\n",
    "    \n",
    "    ############### NEW CODE ##############\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True, drop_last=False)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=True, drop_last=False)\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    valloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, sampler=val_dataset)\n",
    "    \n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea4b61-9fe3-4f9d-830d-b9515bfd9905",
   "metadata": {},
   "source": [
    "#### Step 3) Wrap the Entire Training Scipt in a Main Function\n",
    "\n",
    "The code we write in the main function will be spawed and run on all GPUS indicated in the world size. The Spawning (done later by the torch.multiprocessing module) will determine the rank (which GPU) each process should go to. So again, we will have a parameter for rank but we don't need to worry about it too much.\n",
    "\n",
    "There is another complication though we need to consider: **Batch Normalization**. As we know, BatchNormalization will calculate the mean and standard deviation for a specific batch, but now that we have batches distributed between GPUS we need to somehow bring it all together. To do this we will convert all the BatchNorms with SyncBatchNorms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ead9622-915a-423a-a60a-02ab225e2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rank, world_size):\n",
    "    ### Setup The Environmental Variables and Initialize ###\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    ### Build our Distributed DataLoaders ###\n",
    "    trainloader, valloader = build_distributed_sampler(\"../data/PetImages/\", batch_size=64, world_size=world_size,\n",
    "                                                       rank=rank)\n",
    "\n",
    "    ### Define Model and Convert to SyncBatchNorm ###\n",
    "    model = VanillaAlexNet().to(rank)\n",
    "    model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
    "\n",
    "    ### Set Optimizer and Loss Function ###\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    ### Start Training loop ###\n",
    "    epochs = 5\n",
    "\n",
    "    ### Standard Trainin Loop ###\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if rank == 0:  # Only print when we are using the default node 0 (otherwise everything will print once for each GPU)\n",
    "            print(f\"Starting Epoch {epoch}\")\n",
    "\n",
    "        ### Set Epoch for train and valloader for every epoch. This is necessary for proper shuffling in every iteration\n",
    "        trainloader.sampler.set_epoch(epoch)\n",
    "        valloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        training_accuracies = []\n",
    "        validation_accuracies = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for image, label in trainloader:\n",
    "            image, label = image.to(rank), label.to(rank)\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            ### CALCULATE ACCURACY ###\n",
    "            predictions = torch.argmax(out, axis=1)\n",
    "            accuracy = (predictions == label).sum() / len(predictions)\n",
    "            training_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        for image, label in valloader:\n",
    "            image, label = image.to(rank), label.to(rank)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                ### CALCULATE ACCURACY ###\n",
    "                predictions = torch.argmax(out, axis=1)\n",
    "                accuracy = (predictions == label).sum() / len(predictions)\n",
    "                validation_accuracies.append(accuracy.item())\n",
    "\n",
    "        \n",
    "        ### Convert Lists of Metrics to Tensors, Take the Mean, Store in Corresponing GPU ###\n",
    "        training_loss_mean = torch.mean(torch.tensor(training_losses, dtype=torch.float)).to(rank)\n",
    "        valid_loss_mean = torch.mean(torch.tensor(validation_losses, dtype=torch.float)).to(rank)\n",
    "        training_acc_mean = torch.mean(torch.tensor(training_accuracies, dtype=torch.float)).to(rank)\n",
    "        valid_acc_mean = torch.mean(torch.tensor(validation_accuracies, dtype=torch.float)).to(rank)\n",
    "\n",
    "        ### AGGREGATE LOSSES AND MEANS ACROSS ALL GPUS ###\n",
    "        torch.distributed.all_reduce(training_loss_mean, op=dist.ReduceOp.SUM)\n",
    "        torch.distributed.all_reduce(valid_loss_mean, op=dist.ReduceOp.SUM)\n",
    "        torch.distributed.all_reduce(training_acc_mean, op=dist.ReduceOp.SUM)\n",
    "        torch.distributed.all_reduce(valid_acc_mean, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        ### DIVIDE THE SUM BY NUMBER OF GPUS (WORLD SIZE)\n",
    "        training_loss_mean = training_loss_mean / world_size\n",
    "        valid_loss_mean = valid_loss_mean / world_size\n",
    "        training_acc_mean = training_acc_mean / world_size\n",
    "        valid_acc_mean = valid_acc_mean / world_size\n",
    "\n",
    "        if rank == 0:  # Only print when we are using the default node 0 (otherwise everything will print once for each GPU)\n",
    "            print(\"Training Loss:\", training_loss_mean.item())\n",
    "            print(\"Training Accuracy:\", training_acc_mean.item())\n",
    "            print(\"Validation Loss:\", valid_loss_mean.item())\n",
    "            print(\"Validation Accuracy:\", valid_acc_mean.item())\n",
    "\n",
    "    dist.destroy_process_group()  ## End Training and Remove Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50facac-36b7-4ac5-8542-d40eb96c4c16",
   "metadata": {},
   "source": [
    "### Step 4) Spawn Processes and we are Done!!\n",
    "\n",
    "```\n",
    "world_size = 2\n",
    "mp.spawn(main,\n",
    "         args=(world_size,),\n",
    "         nprocs=world_size\n",
    "    )\n",
    "```\n",
    "\n",
    "We wont be running this inside the Jupyter Notebook as it will give errors but we will have all this in the [ddp.py](ddp.py)!\n",
    "\n",
    "#### Rank\n",
    "Internally, the mp.spawn will generate ranks from [0 to world_size - 1], so if we have 2 GPU's then the options for ranks are 0 and 1. It will then append the additional arguments that we pass in args that the main function needs. Our main function only needed to know the World Size, so our args was just world size, and then again internally the world size will be appended to our current rank and passed to the main function as a tuple.\n",
    "\n",
    "\n",
    "### We Can Now Train Larger Models!!\n",
    "Again, these techniques were applied to a relatively simple model, but the principles will be identical regardless! As a recap again:\n",
    "\n",
    "- If you only have 1 GPU, your only option is **Gradient Accumulation**\n",
    "- If you have multiple GPUS and your model can fit on one of them, then you can do DataParallel, or preferrably, DistributedDataParallel. \n",
    "- If you have multiple GPUS and your model CANNOT fit on them, then you can split the model between GPUS.\n",
    "\n",
    "\n",
    "All the principles above can also be put together. You can do Distributed Data Parallel but also do gradient accumulation. If we have 4 GPUs we can split a model between two of them and then copy it to the other two, so we will be Distributed Data Parallel and Model Parallel! The setup we do is really dependent on the scale of the model you are trying to train. \n",
    "\n",
    "\n",
    "### Next Steps\n",
    "Although it is nice to understand how to build a distributed system yourself, there are other tools that we will explore in the future that can help optimize the workflow without much effort. The two main ones of interest will be **Ray** for MultiGPU Hyperparameter turning and **HuggingFace Accelerate**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
