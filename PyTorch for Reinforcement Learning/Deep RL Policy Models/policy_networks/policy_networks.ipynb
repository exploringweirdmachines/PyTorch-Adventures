{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6b4b78-272b-48e0-97ef-186a4deef6fd",
   "metadata": {},
   "source": [
    "# Policy Networks\n",
    "\n",
    "Enough with all these Values... All of our Q-Learning models that we explored ([DQN](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Reinforcement%20Learning/Intro%20to%20Deep%20Reinforcement%20Learning/Deep%20Q-Learning/deep_q_learning.ipynb), [Double DQN](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Reinforcement%20Learning/Intro%20to%20Deep%20Reinforcement%20Learning/Double%20Deep-Q%20Learning/double_deep_q_learning.ipynb), [Dueling DQN](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Reinforcement%20Learning/Intro%20to%20Deep%20Reinforcement%20Learning/Dueling%20Deep-Q%20Learning/dueling_deep_q_learning.ipynb)) all were solving for fundamentally the same thing:\n",
    "\n",
    "What is the Value of taking a specific action at a specific state? The *Deep* part of the Deep Q-Learning was just a reparametization of the Q-Table, so instead of a giant table of States and Actions, you just have a Neural Network now. \n",
    "\n",
    "But once we had a trained Deep Q-Model what did we do? We needed our **POLICY** which is our end goal. The policy is the learned guidebook (or strategy) that tells us what action to take given the state, and is typically written with the letter $\\pi$. With our trained Q-Model we created our policy by:\n",
    "\n",
    "$$\\pi = arg\\max_a Q(s,a)$$\n",
    "\n",
    "We simply picked the action $a$ at a state $s$ that had the highest value!\n",
    "\n",
    "Well, if our end goal is the Policy anyway, then why not train our Neural Network directly as a Policy network? Forget estimating values, all we care about is what action we should take at a state, so why not just learn that?\n",
    "\n",
    "Therefore, our Neural Network will directly learn the policy $\\pi_\\theta(a|s)$ (policy parameterized by $\\theta$, rather than first learning $Q_\\theta(s,a)$ and then deriving the policy from that!\n",
    "\n",
    "## Policy Gradient Theorem\n",
    "\n",
    "**Credit** to Lilian Weng and this [incredible post](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/#ppg) on Policy Gradient Methods. Much of what I will do will be close to this (and the [Sutton & Barto, 2017, page 287](http://incompleteideas.net/book/bookdraft2017nov5.pdf) Bible for RL). Also I hope you understood the derivation of the Bellman Equation that we did in our [Introduction to RL](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Reinforcement%20Learning/Intro%20to%20Reinforcement%20Learning/Model-Based%20Learning/intro_rl_and_policy_iter.ipynb). We will be using pieces of that derivation here as well!\n",
    "\n",
    "First of all, our goal is still the same. We want to find the policy that maximizes our overall expected return, but we have to go about this a different way. The reward can be written as:\n",
    "\n",
    "$$J(\\theta) = \\sum_{s}d_\\pi(s)V_\\pi(s)$$\n",
    "\n",
    "### Side Note: Stationary Distribution\n",
    "\n",
    "What is $d_\\pi(s)$? It is known as the stationary distribution, a common property of Markov Chains! Lets first define our Markov Chain via is Transition probability matrix. If we pretend there are only 5 states in our environment, it is a matrix identifying the probability of moving from one state to another:\n",
    "\n",
    "$$P_{ij} = P(t+1=j|t=i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7913fba9-3398-44e4-bd1e-98a5b9d95f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video\n",
    "\n",
    "P = np.array([\n",
    "    [0.1, 0.6, 0.0, 0.2, 0.1],\n",
    "    [0.4, 0.2, 0.2, 0.0, 0.2],\n",
    "    [0.0, 0.3, 0.4, 0.2, 0.1],\n",
    "    [0.3, 0.0, 0.3, 0.3, 0.1],\n",
    "    [0.2, 0.1, 0.3, 0.3, 0.1]\n",
    "])\n",
    "\n",
    "def plot_markov_chain(P, labels):\n",
    "    G = nx.DiGraph()\n",
    "    num_states = len(P)\n",
    "\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            if P[i, j] > 0:\n",
    "                G.add_edge(labels[i], labels[j], weight=P[i, j])\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "    edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "    edge_labels = {k: f\"{v:.2f}\" for k, v in edge_labels.items()}\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color='skyblue', font_size=15, font_weight='bold', arrowsize=20)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "    plt.title(\"Markov Chain\")\n",
    "    plt.show()\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "plot_markov_chain(P, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66262b1-3484-4594-8bb0-353096c6d598",
   "metadata": {},
   "source": [
    "We can use this matrix $P$ to show probability of transitions from one state to another, and we can use it to multiply our transitions over and over. Lets say we start at any state uniformly (if we have 5 states, each has a 20% chance that we are in it). \n",
    "\n",
    "We will then keep roaming through the entire chain with the probabilities identified in our transition matrix. The question is, what is the probability of being at a state, as our number of transitions go to infinity? If lots of nodes are connected to a node with high probability, we are likely to end up there. If a node is mostly disconnected, we are less likely to end up there. What we want is the final distribution of these probabilities\n",
    "\n",
    "$$\\pi_n = [P(s_n=A), P(s_n=B), P(s_n=C), P(s_n=D), P(s_n=E)]$$\n",
    "\n",
    "and we want to take the limit as $\\lim_{n \\rightarrow \\infty}\\pi_n$\n",
    "\n",
    "#### Single Transition \n",
    "\n",
    "If we start uniformly, with $\\pi_0 = [\\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}]$ then $\\pi_1 = \\pi_0 P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1de30ed2-9c6f-498a-979b-3bb9644edd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2  0.24 0.24 0.2  0.12]\n"
     ]
    }
   ],
   "source": [
    "pi_0 = np.array([0.2 for _ in range(5)])\n",
    "pi_1 = pi_0 @ P\n",
    "print(pi_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1b013-7e28-4b7c-8514-bab612764c0e",
   "metadata": {},
   "source": [
    "This means, starting from a random position, the likelihood of being in state A after a single transition is 0.2. The likelihood of being in state B after a single transition is 0.24. And the same for the rest!\n",
    "\n",
    "A stationary distribution is one where, when we multiply our probability vector $\\pi$ by our transition matrix, the probability no longer changes (i.e. we have converged). There is two ways to find this: (1) iterative method or (2) solve a system of equations\n",
    "\n",
    "#### Iterative Method\n",
    "\n",
    "All we need to do is multiply $\\pi$ by $P$ repeatedly until the values don't change!\n",
    "\n",
    "![image](figs/stationary_dist.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e87d5030-5fb4-49fd-b133-45d834f477d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: [0.2  0.24 0.24 0.2  0.12]\n",
      "Iteration 1: [0.2   0.252 0.24  0.184 0.124]\n",
      "Iteration 2: [0.2008 0.2548 0.2388 0.1804 0.1252]\n",
      "Iteration 3: [0.20116 0.2556  0.23816 0.1796  0.12548]\n",
      "Iteration 4: [0.201332 0.255812 0.237908 0.179388 0.12556 ]\n",
      "Iteration 5: [0.2013864 0.25589   0.23781   0.1793324 0.1255812]\n",
      "Iteration 6: [0.2014106  0.25591096 0.23777608 0.17931336 0.125589  ]\n",
      "Iteration 7: [0.20141725 0.25592028 0.23776333 0.17930804 0.1255911 ]\n",
      "Iteration 8: [0.20142047 0.25592252 0.23775913 0.17930586 0.12559203]\n",
      "Iteration 9: [0.20142122 0.25592373 0.23775752 0.17930529 0.12559225]\n",
      "Iteration 10: [0.20142165 0.25592396 0.23775701 0.17930501 0.12559237]\n",
      "Iteration 11: [0.20142172 0.25592412 0.23775681 0.17930495 0.1255924 ]\n",
      "Iteration 12: [0.20142178 0.25592414 0.23775675 0.17930491 0.12559241]\n",
      "Iteration 13: [0.20142179 0.25592417 0.23775673 0.1793049  0.12559241]\n",
      "Iteration 14: [0.2014218  0.25592417 0.23775672 0.1793049  0.12559242]\n",
      "Iteration 15: [0.2014218  0.25592417 0.23775672 0.1793049  0.12559242]\n",
      "Iteration 16: [0.2014218  0.25592417 0.23775671 0.1793049  0.12559242]\n",
      "Iteration 17: [0.2014218  0.25592417 0.23775671 0.1793049  0.12559242]\n",
      "Iteration 18: [0.2014218  0.25592417 0.23775671 0.1793049  0.12559242]\n",
      "Iteration 19: [0.2014218  0.25592417 0.23775671 0.1793049  0.12559242]\n"
     ]
    }
   ],
   "source": [
    "iters = 20\n",
    "\n",
    "pi = np.array([0.2 for _ in range(5)])\n",
    "for i in range(iters):\n",
    "    pi = pi @ P\n",
    "    print(f\"Iteration {i}:\", pi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1172a42c-c131-4820-9c47-0dbf2102c7d6",
   "metadata": {},
   "source": [
    "Looks like our iterative method converged! We could go for more iterations but it'll be about the same. This tells us that if we randomly walked around our markov chain for many steps, we would roughly be in:\n",
    "\n",
    "- State A 20% of the time\n",
    "- State B 26% of the time\n",
    "- State C 24% of the time\n",
    "- State D 17% of the time\n",
    "- State E 13% of the time\n",
    "\n",
    "#### Solving a System of Equations\n",
    "\n",
    "The other way to do this to get an exact solution is, if we have our stationary distribution $\\pi$ and we multiply it by our transition matrix $P$, nothing should change, as it should have converged. Therefore we can write:\n",
    "\n",
    "$$\\pi = \\pi P$$\n",
    "\n",
    "And all we have to do is solve for $\\pi$. The only caveat is $\\pi$ is a probability vector, so we need to make sure we have the constraint that:\n",
    "\n",
    "$$\\sum_i \\pi_i = 1$$\n",
    "\n",
    "So we can set up our system like the following:\n",
    "\n",
    "$$\\pi = \\pi P$$\n",
    "$$\\pi - \\pi P = 0$$\n",
    "$$\\pi(I - P) = 0$$\n",
    "$$(I - P)^T\\pi^T = 0$$\n",
    "\n",
    "The only thing we need to add is a row of 1 to our $(I-P)^T$ and a 1 to our output such that we get our constraint included as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7c7514d-08a4-469c-9431-b3781d7d95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 0.9 -0.4  0.  -0.3 -0.2]\n",
      " [-0.6  0.8 -0.3  0.  -0.1]\n",
      " [ 0.  -0.2  0.6 -0.3 -0.3]\n",
      " [-0.2  0.  -0.2  0.7 -0.3]\n",
      " [-0.1 -0.2 -0.1 -0.1  0.9]\n",
      " [ 1.   1.   1.   1.   1. ]]\n",
      "b:\n",
      "[0 0 0 0 0 1]\n",
      "Solution: [0.2014218  0.25592417 0.23775671 0.1793049  0.12559242]\n"
     ]
    }
   ],
   "source": [
    "I_min_P_append = np.concatenate([(np.eye(5) - P).T, np.ones(5).reshape(1,5)])\n",
    "print(\"A:\")\n",
    "print(I_min_P_append)\n",
    "\n",
    "b = np.array([0,0,0,0,0,1])\n",
    "print(\"b:\")\n",
    "print(b)\n",
    "\n",
    "solution, _, _, _ = np.linalg.lstsq(I_min_P_append, b, rcond=-1)\n",
    "\n",
    "print(\"Solution:\", solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3cf0b-153c-4dcb-8c66-2089b9fc4f82",
   "metadata": {},
   "source": [
    "We got the same solution!\n",
    "\n",
    "### Back to Policy Gradient Theorem \n",
    "\n",
    "Now that you know what a stationary distribution is, lets get back to our actual problem!\n",
    "\n",
    "$$J(\\theta) = \\sum_{s}d_\\pi(s)V_\\pi(s)$$\n",
    "\n",
    "Our stationary distribution $d_\\pi(s)$ tells us that if we just played the game (according to some policy $\\pi$) and roamed around, we have our likelihood of being at the different states. We also have our value funciton $V(s)$ that tells us the value of those states. Therefore, our cost function $J(\\theta)$ is just multiplying the two. We weight our Values of every state by how likely we are to be there, and then add it all up! We then want to perform gradient ascent, increasing this cost so we can get the higest returns possible!\n",
    "\n",
    "We can expand on this a little bit more. Remember that our Values are just an expectation of the $Q$ function across the actions we could take at that state (we saw this at the very beginning!) So lets write it like that instead:\n",
    "\n",
    "$$V_\\pi(s) = \\sum_{a}\\pi_\\theta(a|s)Q_\\pi(s,a)$$\n",
    "\n",
    "So our final expression is:\n",
    "\n",
    "$$J(\\theta) = \\sum_{s}d_\\pi(s)\\sum_{a}\\pi_\\theta(a|s)Q_\\pi(s,a)$$\n",
    "\n",
    "Now lets take the derivative, as to train a neural network, we need the gradient of our cost function w.r.t our parameters!\n",
    "\n",
    "$$\\nabla_\\theta J(\\theta) = \\nabla_\\theta\\sum_{s}d_\\pi(s)\\sum_{a}\\pi_\\theta(a|s)Q_\\pi(s,a)$$\n",
    "\n",
    "This is unfortunately basically impossible to do for one major reason, what is the stationary distribution $d_\\pi(s)$? We would have to calculate it over and over again every time our policy was updated! Even more challenging is, in the environments we will work with, the states will be continuous, which means our stationary distribution wont be some discrete distribution over the states, but some continuous density function! And we don't even want $d_\\pi(s)$ but rather its derivative... This is exactly what the Policy Gradient Solves. We rewrite this derivative to simplify our gradient computation and avoid ever having to take this derivative of the stationary distribution $d_\\pi(s)$.\n",
    "\n",
    "#### Policy Gradient Theorem Proof\n",
    "\n",
    "Instead of taking the derivative over our total cost $J(\\theta)$, lets just start with the derivatve of our Value function:\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s)$$\n",
    "$$\\nabla_\\theta \\sum_{a}\\pi_\\theta(a|s)Q_\\pi(s,a)$$\n",
    "\n",
    "Now using our standard product rule from calculus $(AB)' = A'B + B'A$:\n",
    "$$\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s) \\nabla_\\theta Q_\\pi(s,a)$$\n",
    "\n",
    "And remind yourself again, what was your $Q(s,a)$? Lets refer to our Bellman Equation!\n",
    "\n",
    "$$\\text{Bellman Equation: } V_\\pi(s) = \\sum_a \\pi(a|s)\\sum_{s'}\\sum_{r}[r + \\gamma V_{\\pi}(s')]P(s',r|a,s)$$\n",
    "\n",
    "And remember, the Bellman Equation is just the Expectation over our $Q(s,a)$ so lets just grab the argument that refers to $Q$.\n",
    "\n",
    "$$\\text{Q Function: } Q_\\pi(s,a) = \\sum_{s'}\\sum_{r}[r + \\gamma V_{\\pi}(s')]P(s',r|a,s)$$\n",
    "\n",
    "Therefore, for the $\\nabla_\\theta Q_\\pi(s,a)$ function that we need to evaluate, lets plug in the actual form for the $Q(s,a)$ function.\n",
    "\n",
    "$$\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s) \\nabla_\\theta \\sum_{s'}\\sum_{r}[r + \\gamma V_{\\pi}(s')]P(s',r|a,s)$$\n",
    "\n",
    "$$\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s)  \\nabla_\\theta \\sum_{s'}\\sum_{r}rP(s',r|a,s) + \\gamma V_{\\pi}(s')P(s',r|a,s)$$\n",
    "\n",
    "We know that $P(s',r|a,s)$, $\\gamma$, and $r$ is just a constant for the derivative (depends on the environment):\n",
    "\n",
    "$$\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s) \\sum_{s'}\\sum_{r}\\gamma P(s',r|a,s) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "We can now use the probability trick we saw before about marginalizing a distribution $\\sum_aP(a,b) = P(b)$. We can sum over the rewards in this case:\n",
    "\n",
    "$$\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s) \\sum_{s'}\\gamma P(s'|a,s) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "And for simplicty (to better follow the original derivation), we will just ignore $\\gamma$. It is a constant anyway to scale our future Values, so it has no real effect on this derivation. So our final form for this derivative is:\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s) \\sum_{s'} P(s'|a,s) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "Do you notice the recursion here? Our derivative of $\\nabla_\\theta V_\\pi(s)$ includes a derivative for $\\nabla_\\theta V_\\pi(s')$, the future state! So what if we unroll it, we have the form for $\\nabla_\\theta V_\\pi(s)$, just plug that in for our same expression for the next state (this is called unrolling):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_\\theta V_\\pi(s) =\\ & \\sum_{a} \\nabla_\\theta \\pi_\\theta(a|s) Q_\\pi(s,a) + \\pi_\\theta(a|s) \\sum_{s'} P(s'|a,s)\\, \\cdot \\\\\n",
    "& \\sum_{a'}\\nabla_\\theta \\pi_\\theta(a'|s')Q_\\pi(s',a') + \\pi_\\theta(a'|s') \\sum_{s''} P(s''|a',s') \\nabla_\\theta V_{\\pi}(s'')\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can continue unrolling this as much as we want, but this will get messy, so lets see if there is anything we can gather from what we have! Remember, our original goal was to get around computing our stationary distribution $d_\\pi(s)$. But this distribution comes from roaming around an environment for a while and then computing the likelihood of being at every state. Lets see if we can somehow represent this entire question recursively!\n",
    "\n",
    "Let say you start at state $s$ and you want to get to state $x$ after $k$ steps following policy $\\pi_\\theta$. As a shorthand we will represent this as $\\rho_\\pi(s \\rightarrow x, k)$\n",
    "\n",
    "So our trajectory will look kind of like:\n",
    "\n",
    "$$\n",
    "s_1 \\xrightarrow{a \\sim \\pi_\\theta} s_2 \\xrightarrow{a \\sim \\pi_\\theta} s_3 \\xrightarrow{a \\sim \\pi_\\theta} s_4 \\ldots \\xrightarrow{a \\sim \\pi_\\theta} s_{k}=x\n",
    "$$\n",
    "\n",
    "For a single transition (one step so $k=1$) from $s \\rightarrow s'$, the probability of this transition is what it always was! We just sum over all the actions we could take at $s$ and add up the probabilities to our targer $s'$:\n",
    "\n",
    "$$\\rho_\\pi(s \\rightarrow s', k=1) = \\sum_a \\pi_\\theta(a|s)P(s'|s,a)$$\n",
    "\n",
    "Also, if our goal is to get to $x$ in $k$ steps, another way you can think about this is. It means that in $k-1$ steps we can be anywhere we want to be, and then in that last transition we get to our target $x$. More specifically, if your goal is to get to the grocery store in 5 hours, that means you can do whatever you want in the mean time before you end up at the store at the end! So the way we can represent this is as summing over all the states I can transition to, and then in the last step I transition to $x$. This is because I specified that I only want to get to $x$ in $k$ steps!\n",
    "\n",
    "$$\\rho_\\pi(s \\rightarrow x, k) = \\sum_{s'}\\rho_\\pi(s \\rightarrow s', k-1)\\rho_\\pi(s' \\rightarrow x, 1)$$\n",
    "\n",
    "Lets get back to our original expression:\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) + \\pi_\\theta(a|s) \\sum_{s} P(s'|a,s) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "Now that we see the recursion, lets simplify this a bit and write $\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a) = \\phi(s)$ as shorthand.\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\phi(s) + \\sum_{a}\\pi_\\theta(a|s) \\sum_{s'} P(s'|a,s) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "And we can move things around in the sum and get:\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\phi(s) + \\sum_{s'} \\sum_{a}\\pi_\\theta(a|s) P(s'|a,s) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "And now we see our $\\sum_{a}\\pi_\\theta(a|s) P(s'|a,s)$ which we called $\\rho$ and is a transition from $s \\rightarrow s'$ in one step just a few lines earlier! So lets go ahead and use that\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\phi(s) + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1) \\nabla_\\theta V_{\\pi}(s')$$\n",
    "\n",
    "And again, we have our form already for $\\nabla_\\theta V_{\\pi}(s)$, we can just reuse it for $\\nabla_\\theta V_{\\pi}(s')$ to continue the recursion!\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\phi(s) + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1) \\left[\\phi(s') + \\sum_{s''} \\rho_\\pi(s' \\rightarrow s'', k=1) \\nabla_\\theta V_{\\pi}(s'') \\right]$$\n",
    "\n",
    "Let distribute $\\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1)$:\n",
    "\n",
    "$$= \\phi(s) + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1)\\phi(s') + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1) \\sum_{s''} \\rho_\\pi(s' \\rightarrow s'', k=1) \\nabla_\\theta V_{\\pi}(s'')$$\n",
    "\n",
    "$$= \\phi(s) + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1)\\phi(s') + \\sum_{s'}\\sum_{s''}\\rho_\\pi(s \\rightarrow s', k=1) \\rho_\\pi(s' \\rightarrow s'', k=1) \\nabla_\\theta V_{\\pi}(s'')$$\n",
    "\n",
    "What do we have here? We have $\\rho_\\pi(s \\rightarrow s', k=1)$ which is a transition from $s \\rightarrow s'$ in one step, and then $\\rho_\\pi(s' \\rightarrow s'', k=1)$ which is a transition from $s' \\rightarrow s''$ in one step. Isn't that the same as just going from $s \\rightarrow s''$ in two steps? Exactly! So lets merge these two together!\n",
    "\n",
    "$$= \\phi(s) + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1)\\phi(s') + \\sum_{s''}\\rho_\\pi(s \\rightarrow s'', k=2) \\nabla_\\theta V_{\\pi}(s'')$$\n",
    "\n",
    "Do you see the pattern? We can continue this on for as long as we want!\n",
    "\n",
    "$$= \\phi(s) + \\sum_{s'} \\rho_\\pi(s \\rightarrow s', k=1)\\phi(s') + \\sum_{s''}\\rho_\\pi(s \\rightarrow s'', k=2)\\phi(s'') + \\sum_{s'''}\\rho_\\pi(s \\rightarrow s''', k=3)\\phi(s''') + \\ldots $$\n",
    "\n",
    "So we can finally write a simplified form:\n",
    "\n",
    "$$\\nabla_\\theta V_\\pi(s) = \\sum_{x\\in S}\\sum_{k=0}^\\infty \\rho_\\pi(s \\rightarrow x, k)\\phi(x)$$\n",
    "\n",
    "This is great! We just took the derivative without dealing with the annoying stationary distribution directly! Lets wrap this up then! We still want our stationary distribution in our cost expression, but with what we have (recursively exploring the environment for $k$ steps and tracking the probability of those transitions, we should be able to get it back! To follow the notation of the book, lets say that we start at some random state $s_0$ and our goal is to get to $s$. \n",
    "\n",
    "$$\\nabla_\\theta J(\\theta) = \\nabla_\\theta V_\\pi(s_0)$$\n",
    "$$= \\sum_{s\\in S}\\sum_{k=0}^\\infty \\rho_\\pi(s_0 \\rightarrow s, k)\\phi(s)$$\n",
    "\n",
    "As a shorthand, the book says that $\\sum_{k=0}^\\infty \\rho_\\pi(s_0 \\rightarrow s, k) = \\eta(s)$\n",
    "$$= \\sum_{s\\in S}\\eta(s)\\phi(s)$$\n",
    "\n",
    "Now $\\eta(s)$ is an accumulation of transition probabilities over infinitely long trajectories, but it would be helpful if we could normalize $\\eta(s)$ to be a probability distribution over the states. We can easily normalize it!\n",
    "\n",
    "$$= \\left(\\sum_{s\\in S}\\eta(s)\\right)\\sum_{s\\in S}\\frac{\\eta(s)}{\\sum_{s\\in S}\\eta(s)}\\phi(s)$$\n",
    "\n",
    "This sum is just a constant so we can write:\n",
    "\n",
    "$$\\propto \\sum_{s\\in S}\\frac{\\eta(s)}{\\sum_{s\\in S}\\eta(s)}\\phi(s)$$\n",
    "\n",
    "Lets think a bit about what is going on in the expression $\\frac{\\eta(s)}{\\sum_{s\\in S}\\eta(s)}$. This is a probability distribution created from elements of infinitely long trajectories on our environment. This distribution weights the likelihood of being at the different states. Well... isn't that exactly $d_\\pi(s)$? Thats exactly right! Our proportion here is a probability over all states, and this probability was constructed by normalizing the probabilites of infinitely long explorations on on environment, therefore it is exactly the stationary distribution we saw earlier! Thats neat, our stationary distribution showed up without us ever directly computing it!\n",
    "\n",
    "So lets wrap this up:\n",
    "\n",
    "$$ = \\sum_{s\\in S}d_\\pi(s)\\phi(s)$$\n",
    "\n",
    "and we know that $\\phi(s) = \\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a)$ as that is what we set it to, to begin with, so our final substitution:\n",
    "\n",
    "$$ \\nabla_\\theta J(\\theta) \\propto \\sum_{s}d_\\pi(s)\\sum_{a}\\nabla_\\theta \\pi_\\theta(a|s)Q_\\pi(s,a)$$\n",
    "\n",
    "And that is exactly our form from before, but we have managed to set up our derivation in a way that avoid ever taking the gradient on $d_\\pi(s)$!\n",
    "\n",
    "Although we are technically done, this isn't the form you traditionally see for Policy Gradients, so lets do the last step! Lets multiply and divide by $\\pi(a|s)$\n",
    "\n",
    "$$\\sum_{s}d_\\pi(s)\\sum_{a}\\pi_\\theta(a|s) Q_\\pi(s,a)\\frac{\\nabla_\\theta \\pi_\\theta(a|s)}{\\pi_\\theta(a|s)}$$\n",
    "\n",
    "Remeber, our policy $\\pi_\\theta(a|s)$ is a probability distribution. It provides the probability of taking some action at some state. Similarly, $d_\\pi(s)$ is also a distribution over the states. But if thats the case, then isn't this just an expecation. Remember that $\\sum p(x) f(x) = E_p[f(x)]$. In our case its an expectation over the policy and our stationary distribution (or more specifically an expectation over every combination of states and actions weighted by the likelihood of being at that state)\n",
    "\n",
    "$$\\sum_{s}\\sum_{a}\\left(d_\\pi(s)\\pi_\\theta(a|s)\\right) Q_\\pi(s,a)\\frac{\\nabla_\\theta \\pi_\\theta(a|s)}{\\pi_\\theta(a|s)}$$\n",
    "$$E_{s\\sim d_\\pi, a \\sim \\pi} \\left[Q_\\pi(s,a)\\frac{\\nabla_\\theta \\pi_\\theta(a|s)}{\\pi_\\theta(a|s)}\\right]$$\n",
    "\n",
    "And for simplicity we can write $s\\sim d_\\pi, a \\sim \\pi$ as just $\\pi$ as both of these things come from and follow the policy (on-policy):\n",
    "\n",
    "$$E_{\\pi} \\left[Q_\\pi(s,a)\\frac{\\nabla_\\theta \\pi_\\theta(a|s)}{\\pi_\\theta(a|s)}\\right]$$\n",
    "\n",
    "And for the last simplification, we know that $\\ln(f(x))' = f'(x)/f(x)$, therefore we can go the other way and write:\n",
    "\n",
    "$$\\nabla_\\theta J(\\theta) \\propto E_{\\pi} \\left[Q_\\pi(s,a)\\nabla_\\theta \\ln\\pi_\\theta(a|s)\\right]$$\n",
    "\n",
    "And thats it! We have a way to take the derivative of this cost function in a computable way. Now we need a way to actually use this in practice. The first method to do this is called REINFORCE:\n",
    "\n",
    "### REINFORCE Algorithm (Monte-Carlo Policy Gradients)\n",
    "\n",
    "The problem with our expression earlier is that we don't actually have $Q_\\pi(s,a)$. And like I promised, we will not be (atleast right now) training a Neural Network to estimate the values, only the Policy $\\pi$. But can we get a guesstimate for $Q_\\pi(s,a)$? Of course!\n",
    "\n",
    "Remember, at the very start of our derivation of the Bellman Equation we stated $G_t$ was our expected future rewards:\n",
    "\n",
    "$$G_t = \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1}$$\n",
    "\n",
    "And when we were computing our Values $V(s)$ we were really saying that our Values were the expected returns:\n",
    "\n",
    "$$V(s) = E[G_t|s]$$\n",
    "\n",
    "Well our Values is just an expectation over the actions, therefore our Q Values can be similarly written as:\n",
    "\n",
    "$$Q(s,a) = E[G_t|s,a]$$\n",
    "\n",
    "It is the expected future returns given that we are at a state and took a specific action.\n",
    "\n",
    "Our $E_\\pi$ is already doing an expectation over the state $s$ and the action $a$, so why dont we use $G_t$ in place of $Q(s,a)$? This is exactly the REINFORCE Algorithm.\n",
    "\n",
    "$$E_{\\pi} \\left[G_t\\nabla_\\theta \\ln\\pi_\\theta(a|s)\\right]$$\n",
    "\n",
    "This has two implications:\n",
    "\n",
    "1) We can estimate $G_t$ by interacting with the environment to generate an experience trajectory. Then we can simply use the formula to take our sequence of experiences and compute $G_t$ directly.\n",
    "2) This makes our implementation a [Monte Carlo Method](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Reinforcement%20Learning/Intro%20to%20Reinforcement%20Learning/Model-Free%20Learning/monte_carlo.ipynb). Remember that unlike Q-Learning and SARSA where we learned something at every step of interaction leveraging bootstrapped estimates, Monte Carlo required us to complete a full trajectory first to compute $G_t$ and then we could update our estimate for $Q(s,a)$. In REINFORCE we will have to do the same thing. We no longer have a replay buffer. We play the game till termination, compute $G_t$ and then update our model!\n",
    "\n",
    "Also, a small trick used for stabilizing training is to normalize $G_t$ after computing it. This way we have less variance in our estimates! We can no longer train on batches to average over to remove noise, so we have to do this instead!\n",
    "\n",
    "Therefore our algorithm is:\n",
    "\n",
    "1) Generate a Trajectory\n",
    "2) For every step in the the trajectory compute $G_t$\n",
    "3) Update the policy\n",
    "\n",
    "## Lets Implement It!\n",
    "\n",
    "You should have a pretty good idea of whats going on, but lets implement it to make sure we understand everything!\n",
    "\n",
    "### Policy Network\n",
    "\n",
    "We are still playing on the Lunar Lander game, so our model wont look all that different that before. But, we are trying to learn a policy, so our output should be a probability distribution over the actions (rather than outputting the value of an action like we did before).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a818d62-0bad-48bc-ae86-b123fdc652f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_state_features=8, \n",
    "                 num_actions=4,\n",
    "                 hidden_features=128):\n",
    "        \n",
    "        super(PolicyNetwork, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_state_features, hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features,hidden_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        pi = F.softmax(self.fc2(x), dim=-1)\n",
    "        return pi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a086f-3162-41a7-9849-ad8f8ab2453c",
   "metadata": {},
   "source": [
    "### Training our Model \n",
    "\n",
    "Training is pretty straight forward. We will play for some number of games, and for each game, we will store a trajectory. From that we can compute our $G_t$ and use it to update our model!\n",
    "\n",
    "#### Compute Trajectory\n",
    "\n",
    "This is going to be basically the same as when we had done the Monte Carlo Model, except for one thing. We dont want the final $G$, but rather all the intermediate $G_t$ values as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bafd3a5f-ad82-437b-aec7-d83b0521c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(reward_trajectory, gamma=0.99):\n",
    "\n",
    "    ### Initialize Returns ###\n",
    "    G_t = 0\n",
    "\n",
    "    ### Reverse and Compute Returns ###\n",
    "    for r_t in reversed(reward_trajectory):\n",
    "\n",
    "        ### Compute G_t ###\n",
    "        G_t = r_r + gamma * G_t\n",
    "\n",
    "        ### We are computing G_t from last timestep to beginning ###\n",
    "        \n",
    "        returns.insert\n",
    "\n",
    "    return torch.tensor(returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e3b46-23d2-41ac-9459-736eda5e6a99",
   "metadata": {},
   "source": [
    "### Training Script\n",
    "\n",
    "Lets now follow the procedure we outlined! \n",
    "\n",
    "1) For every Game\n",
    "    1) Play a full trajectory (using our ```PolicyNetwork``` to determine actions -> ON-POLICY)\n",
    "    2) Compute the returns $G_t$ at every timestep\n",
    "    3) Store the log probability output from our policy at every timestep\n",
    "    4) Multiply the log probability by the returns\n",
    "    5) We could either update our model at every timestep, or just add it all together and update it\n",
    "    6) Multiply loss by -1 as we want to maximize $J(\\theta)$, so minimize the negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4af2cde9-e98b-4d69-860b-f501839dcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, \n",
    "          input_state_features=8, \n",
    "          num_actions=4,\n",
    "          hidden_features=128,\n",
    "          learning_rate=0.0005,\n",
    "          episodes=1000, \n",
    "          running_avg_steps=10, \n",
    "          print_freq=5,\n",
    "          gamma=0.99):\n",
    "\n",
    "    ### Define Model ###\n",
    "    policy_network = PolicyNetwork(\n",
    "        input_state_features=input_state_features, \n",
    "        num_actions=num_actions,\n",
    "        hidden_features=hidden_features\n",
    "    )\n",
    "\n",
    "    ### Define Optimizer ###\n",
    "    optimizer = optim.Adam(model.parameters, lr=learning_rate)\n",
    "\n",
    "    ### Store Rewards for Each Game ###\n",
    "    log = {\"scores\": [], \n",
    "           \"running_avg_scores\": []}\n",
    "    \n",
    "    ### For Every Game ###\n",
    "    for i in range(episodes):\n",
    "\n",
    "        ### Start Game ###\n",
    "        state, _ = env.reset()\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            ### Conver State to Tensor and Add BAtch Dimension ###\n",
    "            state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            ### Use Policy Network to Decide Action ###\n",
    "            action_probs = policy(state)\n",
    "\n",
    "            ### Sample from the action probs ###\n",
    "            selected_action = torch.multinomial(action_probs, num_samples=1).item()\n",
    "\n",
    "            ### Get the Log Prob of the Action ###\n",
    "            log_prob = torch.log(action_probs[0, selected_action.item()])\n",
    "\n",
    "            ### Take Action in the Game ###\n",
    "            next_state, reward, terminal, truncated, _ = env.step(action)\n",
    "\n",
    "            ### Store Everything ###\n",
    "            log_probs.append(log_prob)\n",
    "            rewards.append(reward)\n",
    "            \n",
    "            ### Check if we are done ###\n",
    "            done = terminal or truncated\n",
    "\n",
    "            ### Set the state as the next state ###\n",
    "            state = next_state\n",
    "\n",
    "        ### Once the Game is Over Compute Discounted Returns G_t ###\n",
    "        returns = compute_returns(rewards, gamma)\n",
    "\n",
    "        ### Normalize the Returns ###\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n",
    "\n",
    "        ### Policy Gradient Update ###\n",
    "        loss = -torch.sum(torch.stack(log_probs) * returns)\n",
    "\n",
    "        ### Update Policy ###\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ### Store Total Reward for Episode ###\n",
    "        total_rewards = sum(rewards)\n",
    "\n",
    "        ### Log ###\n",
    "        log[\"scores\"].append(total_rewards)\n",
    "        running_avg_score = np.mean(log[\"scores\"][-running_avg_steps:])\n",
    "        log[\"running_avg_scores\"].append(running_avg_score)\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(f\"Episode {i}, Total Reward: {total_rewards}\")\n",
    "\n",
    "    return policy_network, log\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
